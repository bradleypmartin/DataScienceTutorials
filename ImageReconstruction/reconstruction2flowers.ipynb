{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Our image frag and shuffle worked out. Time to import that work here and build a starter\n",
    "# reconstruction algo (we'll refine the strategy after a simple, naive-ish approach)\n",
    "\n",
    "# Importing tools\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import math\n",
    "\n",
    "# Reading image from .jpg data\n",
    "im = Image.open( 'TestImages/flowers.jpg' ).rotate(-90)\n",
    "\n",
    "# Optional original image visualization in-notebook\n",
    "#im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# converting image data to numpy array\n",
    "pix = np.array(im);\n",
    "\n",
    "# We've noticed that the rotated (kitty trial) image has a padded black border,\n",
    "# which we want to remove (hard-coded here) for reconstruction (artificial original\n",
    "# border = ability to 'cheat' the reconstruction algo!)\n",
    "RL = 0\n",
    "RU = 3024\n",
    "CL = 550\n",
    "CU = 3500\n",
    "pixCropped = pix[RL:RU,CL:CU,0:3]\n",
    "\n",
    "# optional image conversion and printing of cropped image data\n",
    "imCropped = Image.fromarray(pixCropped,'RGB')\n",
    "#imCropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now we want to let the user/test administrator pick a number of\n",
    "# row partitions and column partitions for fragging the image.\n",
    "\n",
    "# test administrator-defined partitions\n",
    "rowPartitions = 5\n",
    "colPartitions = 3\n",
    "\n",
    "# storing values for # total rows, cols (pixels)\n",
    "pixelRows = pixCropped.shape[0];\n",
    "pixelCols = pixCropped.shape[1];\n",
    "\n",
    "# row, column length of partitions\n",
    "rowInterval = math.ceil(pixelRows/rowPartitions);\n",
    "colInterval = math.ceil(pixelCols/colPartitions);\n",
    "\n",
    "#(optional) preparing and printing a preliminary impression of partitioning\n",
    "pixPartitioned1 = np.copy(pixCropped)\n",
    "\n",
    "# row partitions\n",
    "for i in range(1,rowPartitions):\n",
    "    rowBegin = i*rowInterval-4\n",
    "    rowEnd   = i*rowInterval+5\n",
    "    pixPartitioned1[rowBegin:rowEnd,:,:] = 255\n",
    "        \n",
    "# column partitions\n",
    "for j in range(1,colPartitions):\n",
    "    colBegin = j*colInterval-4\n",
    "    colEnd   = j*colInterval+5\n",
    "    pixPartitioned1[:,colBegin:colEnd,:] = 255\n",
    "\n",
    "# printing out a concept illustration of the fragmentation\n",
    "imPartitioned1 = Image.fromarray(pixPartitioned1)\n",
    "#imPartitioned1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# determining number of total image fragments based on user input\n",
    "numFragments = rowPartitions*colPartitions\n",
    "\n",
    "# we can shuffle these flattened indices with a random permutation:\n",
    "shufFragIndices = np.random.permutation(numFragments)\n",
    "\n",
    "# now we'll define our overlap and offsets.\n",
    "offsetMax = 2\n",
    "\n",
    "overlapPix = 10\n",
    "\n",
    "# ensuring overlap algo will work (sufficient overlap for offsets)\n",
    "overlapPix = max(overlapPix,3*offsetMax)\n",
    "\n",
    "# using these parameters, we'll define an array of x,y pixel\n",
    "# offsets for each image fragment\n",
    "xyOffsets = np.random.randint(2*offsetMax+1,size=(numFragments,2))-offsetMax\n",
    "#xyOffsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We'll initialize and fill a 4-D (!) array to handle all the frags in the shuffled\n",
    "# order given by shufFragIndices.\n",
    "pixFrags = np.zeros((numFragments,rowInterval + 2*overlapPix,colInterval + 2*overlapPix,3),dtype='uint8')\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    # block indices for starting fragmentation\n",
    "    blockRowInd = shufFragIndices[i] // colPartitions\n",
    "    blockColInd = shufFragIndices[i] % colPartitions\n",
    "    \n",
    "    # defining part of original image given over to fragment 'i'\n",
    "    # (including overlap and x/y offset)\n",
    "    startRow = blockRowInd*rowInterval - overlapPix + xyOffsets[i,0]\n",
    "    endRow = startRow + rowInterval + 2*overlapPix\n",
    "    startCol = blockColInd*colInterval - overlapPix + xyOffsets[i,1]\n",
    "    endCol = startCol + colInterval + 2*overlapPix\n",
    "    \n",
    "    # culling interval back in the case of original image overflow/underflow\n",
    "    if startRow < 0:\n",
    "        startRow = abs(xyOffsets[i,0])\n",
    "        endRow = rowInterval + 2*overlapPix + abs(xyOffsets[i,0])\n",
    "    elif endRow > pixCropped.shape[0]:\n",
    "        startRow = pixCropped.shape[0] - rowInterval - 2*overlapPix - abs(xyOffsets[i,0])\n",
    "        endRow = pixCropped.shape[0] - abs(xyOffsets[i,0])\n",
    "        \n",
    "    if startCol < 0:\n",
    "        startCol = abs(xyOffsets[i,1])\n",
    "        endCol = colInterval + 2*overlapPix + abs(xyOffsets[i,1])\n",
    "    elif endCol > pixCropped.shape[1]:\n",
    "        startCol = pixCropped.shape[1] - colInterval - 2*overlapPix - abs(xyOffsets[i,1])\n",
    "        endCol = pixCropped.shape[1] - abs(xyOffsets[i,1])\n",
    "    \n",
    "    # now we fill in pixFrags (preallocated shape) with shuffled and offset data from\n",
    "    # pixCropped.\n",
    "    pixFrags[i,:,:,:] = pixCropped[startRow:endRow,startCol:endCol,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# (Optional) We can now assemble a shuffled view of the original photo!\n",
    "pixShuffled = np.zeros((rowInterval*rowPartitions,colInterval*colPartitions,3),dtype = 'uint8')\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    blockRowInd = i // colPartitions\n",
    "    blockColInd = i % colPartitions\n",
    "    \n",
    "    startRow = rowInterval*blockRowInd\n",
    "    endRow = startRow + rowInterval\n",
    "    \n",
    "    startCol = colInterval*blockColInd\n",
    "    endCol = startCol + colInterval\n",
    "     \n",
    "    fragRS = overlapPix\n",
    "    fragRE = rowInterval + overlapPix\n",
    "    \n",
    "    fragCS = overlapPix\n",
    "    fragCE = colInterval + overlapPix\n",
    "    \n",
    "    pixShuffled[startRow:endRow,startCol:endCol,:] = pixFrags[i,fragRS:fragRE,fragCS:fragCE,:]\n",
    "    \n",
    "imShuffled1 = Image.fromarray(pixShuffled)\n",
    "#imShuffled1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Here begins the first reconstruction algorithm!\n",
    "\n",
    "# Since we start with the shuffled collection of subimage data\n",
    "# in the 4-D array of pixFrags, and since we start with no idea\n",
    "# of how they relate, we'll need to initialize and then work toward\n",
    "# filling out a graph of relationships between the different images.\n",
    "\n",
    "# The assumption we'll operate under during this project is that, as\n",
    "# we've set the images up, the graph we'll need is very simple and rigidly-\n",
    "# structured...each image points to LEFT, RIGHT, ABOVE, and BELOW neighbors\n",
    "# (with the exception of edge and corner cases).  We'll also have to account\n",
    "# for a random offset relative to each neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Key to the graph: for each subimage 'i', we'll store a 4 x 3 x 3 array of\n",
    "# neighbor data. Out of the four 3-tuples, the SECOND index will point to:\n",
    "\n",
    "# [i,0,0] contains the ith image's LEFT\n",
    "#         neighbor's FIRST index in pixFrags.\n",
    "# [i,1,0] contains the ith image's RIGHT\n",
    "#         neighbor's FIRST index in pixFrags.\n",
    "# [i,2,0] contains the ith image's ABOVE\n",
    "#         neighbor's FIRST index in pixFrags.\n",
    "# [i,3,0] contains the ith image's BELOW\n",
    "#         neighbor's FIRST index in pixFrags.\n",
    "\n",
    "# The second set of tuples ([i,0,1],[i,1,1],[i,2,1],[i,3,1])\n",
    "# will contain X-OFFSET data (relative to the respective neighbor).\n",
    "\n",
    "# The third set of tuples ([i,0,2],[i,1,2],[i,2,2],[i,3,2])\n",
    "# will contain Y-OFFSET data (relative to the respective neighbor).\n",
    "\n",
    "# We'll initialize everything to -1 (a negative flag indicates no\n",
    "# matches have yet been made on the corresponding side).\n",
    "\n",
    "# Below, we'll compute a true graph of where all relationships SHOULD\n",
    "# end up in the reconstruction graph (DEBUGGING/ANALYTICS PURPOSES ONLY)\n",
    "trueGraph = -1*np.ones((numFragments,4))\n",
    "for i in range(0,numFragments):\n",
    "    tempRowIdx = shufFragIndices[i] // colPartitions\n",
    "    tempColIdx = shufFragIndices[i] % colPartitions\n",
    "    \n",
    "    # determining left neighbor in original (and then shuffled) graph\n",
    "    leftColIdx = tempColIdx-1\n",
    "    if leftColIdx >= 0:\n",
    "        leftNeighborIdx = tempRowIdx*colPartitions + leftColIdx\n",
    "        for j in range(0,numFragments):\n",
    "            if shufFragIndices[j] == leftNeighborIdx: \n",
    "                trueGraph[i,0] = j\n",
    "\n",
    "    # determining right neighbor in original (and then shuffled) graph\n",
    "    rightColIdx = tempColIdx+1\n",
    "    if rightColIdx < colPartitions:\n",
    "        rightNeighborIdx = tempRowIdx*colPartitions + rightColIdx\n",
    "        for j in range(0,numFragments):\n",
    "            if shufFragIndices[j] == rightNeighborIdx:\n",
    "                trueGraph[i,1] = j\n",
    "\n",
    "    # determining upper neighbor in original (and then shuffled) graph\n",
    "    upperRowIdx = tempRowIdx-1\n",
    "    if upperRowIdx >= 0:\n",
    "        upperNeighborIdx = upperRowIdx*colPartitions + tempColIdx\n",
    "        for j in range(0,numFragments):\n",
    "            if shufFragIndices[j] == upperNeighborIdx:\n",
    "                trueGraph[i,2] = j\n",
    "\n",
    "    # determining lower neighbor in original (and then shuffled) graph\n",
    "    lowerRowIdx = tempRowIdx+1\n",
    "    if lowerRowIdx < rowPartitions:\n",
    "        lowerNeighborIdx = lowerRowIdx*colPartitions + tempColIdx\n",
    "        for j in range(0,numFragments):       \n",
    "            if shufFragIndices[j] == lowerNeighborIdx:\n",
    "                trueGraph[i,3] = j\n",
    "        \n",
    "#print(trueGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Okay! How do we start filling out this graph? For a naive first approach,\n",
    "# we can simply \"go down the line\" in pixFrags, looking for matches in all the\n",
    "# other subimages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fragmentGraph = -1*np.ones((numFragments,4,3))\n",
    "\n",
    "###############################################\n",
    "### DETERMINING LEFT -> RIGHT RELATIONSHIPS ###\n",
    "###############################################\n",
    "\n",
    "fragsDim = pixFrags.shape\n",
    "fragsHeight = fragsDim[1]\n",
    "fragsWidth  = fragsDim[2]\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    # starting by designating a current \"pivot\" position\n",
    "    # where we're determining key graph relationships\n",
    "    pivotFrag = pixFrags[i,:,:,:]\n",
    "    \n",
    "    for j in range(0,numFragments):\n",
    "        # don't want to compare to self!\n",
    "        \n",
    "        bigBreak = False\n",
    "        \n",
    "        if j != i:\n",
    "            # let's begin in the middle of the two images and\n",
    "            # try tentative offsets/matching data subsequences from there.\n",
    "            queryFrag = pixFrags[j,:,:,:]\n",
    "            \n",
    "            # for this preliminary trial, we'll pivot on the outermost\n",
    "            # rows and columns of pivotFrag's data, probing for matching\n",
    "            # subsequences in queryFrag (where we'll have to look through\n",
    "            # a non-trivial range of columns and rows (due to overlap/offset))\n",
    "            \n",
    "            # declaring bounds for subsequence search\n",
    "            maxMatchWidth = colInterval//2\n",
    "            maxMatchHeight = rowInterval//2\n",
    "            \n",
    "            maxWidthPush = maxMatchWidth//2\n",
    "            maxHeightPush = maxMatchHeight//2\n",
    "            \n",
    "            # let's start comparing the right side of pivotFrag\n",
    "            # with the left side of queryFrag.\n",
    "            midRowPivot = fragsHeight//2\n",
    "            midColPivot = fragsWidth//2\n",
    "            \n",
    "            # looking for small comparison subsets at first (then building out to confirm)\n",
    "            midPivotMat = (pivotFrag[midRowPivot-3:midRowPivot+3,fragsWidth-1,:]\n",
    "                           .astype('int32'))\n",
    "            bigPivotMat = (pivotFrag[midRowPivot-maxHeightPush:midRowPivot+maxHeightPush,\n",
    "                                     fragsWidth-1,:]).astype('int32')\n",
    "            \n",
    "            tunnelDepth = 3\n",
    "            tempQueryXIdx = tunnelDepth\n",
    "            \n",
    "            # regarding limits of the search: we may have to 'tunnel' as much as\n",
    "            # 3*overlapPix pixels + 2*offsetMax into the neighbor to find a match due to how\n",
    "            # these overlaps work near the original image boundary.\n",
    "            \n",
    "            # NOTE: the situation is different if we only have 2 column partitions!!!\n",
    "            #       need to push x all the way to 4*overlapPix!\n",
    "            xOverlapFactor = 3\n",
    "            if colPartitions == 2:\n",
    "                xOverlapFactor = 4\n",
    "            \n",
    "            while tempQueryXIdx < xOverlapFactor*overlapPix + 2 + 2*offsetMax:\n",
    "                \n",
    "                tempYOffset = -3*offsetMax\n",
    "                while tempYOffset < 3*offsetMax + 2:\n",
    "                    \n",
    "                    qRS = midRowPivot - 3 + tempYOffset\n",
    "                    qRE = midRowPivot + 3 + tempYOffset\n",
    "\n",
    "                    # what we're creating here is an initial comparison\n",
    "                    # sliding window of 7 pixels total (3 up, 3 down).\n",
    "                    # if these are \"close enough\" to each other, we'll push\n",
    "                    # the comparison out to try and verify a match.\n",
    "                    \n",
    "                    # let's try and anticipate some possible corruption/bias in our\n",
    "                    # comparison here.\n",
    "                    tempQueryMat = queryFrag[qRS:qRE,tempQueryXIdx,:].astype('int32')\n",
    "                    tempDiffMat = abs(tempQueryMat-midPivotMat)\n",
    "                    \n",
    "                    # being in uint8, with 3 channels, let's look for similarity\n",
    "                    # (7*1*3 = 21 comparison pixel window)\n",
    "                    if sum(sum(tempDiffMat)) < 10*tempDiffMat.size:\n",
    "                        # in the case of a close preliminary match, we'll expand the\n",
    "                        # compare to a much bigger window.\n",
    "                        qRS = midRowPivot - maxHeightPush + tempYOffset\n",
    "                        qRE = midRowPivot + maxHeightPush + tempYOffset\n",
    "                        \n",
    "                        bigQueryMat = queryFrag[qRS:qRE,tempQueryXIdx,:].astype('int32')    \n",
    "                        tempDiffMat = abs(bigQueryMat-bigPivotMat)\n",
    "                        \n",
    "                        if sum(sum(tempDiffMat)) <= 5*tempDiffMat.size:\n",
    "                            # in the case of a 'big match' we'll tunnel even further\n",
    "                            # and see if the match continues.\n",
    "                            \n",
    "                            for xTunnel in range(1,tunnelDepth):\n",
    "                                bigQueryMat = queryFrag[qRS:qRE,tempQueryXIdx-xTunnel,:].astype('int32')\n",
    "                                bigPivotMatTemp = (pivotFrag[midRowPivot-maxHeightPush:midRowPivot+maxHeightPush,\n",
    "                                                         fragsWidth-1-xTunnel,:]).astype('int32')\n",
    "                                tempDiffMat = abs(bigQueryMat-bigPivotMatTemp)\n",
    "                                \n",
    "                                if sum(sum(tempDiffMat)) > 2*tempDiffMat.size:\n",
    "                                    break\n",
    "                                elif xTunnel == tunnelDepth-1 :\n",
    "                                    # remember that we're in the left-pivot-to-right-query\n",
    "                                    # comparison scheme right here.\n",
    "                                    fragmentGraph[i,1,0] = j\n",
    "                                    fragmentGraph[i,1,1] = tempQueryXIdx\n",
    "                                    fragmentGraph[i,1,2] = tempYOffset\n",
    "                                    bigBreak = True;\n",
    "                    \n",
    "                    # if we've found a match, break from the grind in Y and go\n",
    "                    # to next pivot fragment (this'll take a couple break statements)\n",
    "                    if(bigBreak):\n",
    "                        break\n",
    "                    else:\n",
    "                        tempYOffset += 1\n",
    "                \n",
    "                # if we've found a match, break from the grind in X tunneling\n",
    "                if(bigBreak):\n",
    "                    break\n",
    "                else:\n",
    "                    tempQueryXIdx += 1\n",
    "            \n",
    "            # here's the limit of the i/j frag pair testing (if i != j)\n",
    "        \n",
    "        # now, IMPORTANT: if we've found a match and reached here, we\n",
    "        # DON'T want to break but rather CONTINUE to the next pivot fragment.\n",
    "        if(bigBreak):\n",
    "            continue\n",
    "            \n",
    "###############################################\n",
    "### DETERMINING RIGHT -> LEFT RELATIONSHIPS ###\n",
    "###############################################\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    # starting by designating a current \"pivot\" position\n",
    "    # where we're determining key graph relationships\n",
    "    pivotFrag = pixFrags[i,:,:,:]\n",
    "    \n",
    "    for j in range(0,numFragments):\n",
    "        # don't want to compare to self!\n",
    "        \n",
    "        bigBreak = False\n",
    "        \n",
    "        if j != i:\n",
    "            # let's begin in the middle of the two images and\n",
    "            # try tentative offsets/matching data subsequences from there.\n",
    "            queryFrag = pixFrags[j,:,:,:]\n",
    "            \n",
    "            # for this preliminary trial, we'll pivot on the outermost\n",
    "            # rows and columns of pivotFrag's data, probing for matching\n",
    "            # subsequences in queryFrag (where we'll have to look through\n",
    "            # a non-trivial range of columns and rows (due to overlap/offset))\n",
    "            \n",
    "            # declaring bounds for subsequence search\n",
    "            maxMatchWidth = colInterval//2\n",
    "            maxMatchHeight = rowInterval//2\n",
    "            \n",
    "            maxWidthPush = maxMatchWidth//2\n",
    "            maxHeightPush = maxMatchHeight//2\n",
    "            \n",
    "            # let's start comparing the right side of pivotFrag\n",
    "            # with the left side of queryFrag.\n",
    "            midRowPivot = fragsHeight//2\n",
    "            midColPivot = fragsWidth//2\n",
    "            \n",
    "            # looking for small comparison subsets at first (then building out to confirm)\n",
    "            midPivotMat = (pivotFrag[midRowPivot-3:midRowPivot+3,0,:]\n",
    "                           .astype('int32'))\n",
    "            bigPivotMat = (pivotFrag[midRowPivot-maxHeightPush:midRowPivot+maxHeightPush,\n",
    "                                     0,:]).astype('int32')\n",
    "            \n",
    "            tempQueryXIdx = fragsWidth-1-tunnelDepth\n",
    "            \n",
    "            # regarding limits of the search: we may have to 'tunnel' as much as\n",
    "            # 3*overlapPix pixels + 2*offsetMax into the neighbor to find a match due to how\n",
    "            # these overlaps work near the original image boundary.\n",
    "            \n",
    "            # NOTE: the situation is different if we only have 2 column partitions!!!\n",
    "            #       need to push x all the way to 4*overlapPix!\n",
    "            xOverlapFactor = 3\n",
    "            if colPartitions == 2:\n",
    "                xOverlapFactor = 4\n",
    "            \n",
    "            while tempQueryXIdx > fragsWidth-1-(xOverlapFactor*overlapPix + 2 + 2*offsetMax):\n",
    "                \n",
    "                tempYOffset = -3*offsetMax\n",
    "                while tempYOffset < 3*offsetMax + 2:\n",
    "                    \n",
    "                    qRS = midRowPivot - 3 + tempYOffset\n",
    "                    qRE = midRowPivot + 3 + tempYOffset\n",
    "\n",
    "                    # what we're creating here is an initial comparison\n",
    "                    # sliding window of 7 pixels total (3 up, 3 down).\n",
    "                    # if these are \"close enough\" to each other, we'll push\n",
    "                    # the comparison out to try and verify a match.\n",
    "                    \n",
    "                    # let's try and anticipate some possible corruption/bias in our\n",
    "                    # comparison here.\n",
    "                    tempQueryMat = queryFrag[qRS:qRE,tempQueryXIdx,:].astype('int32')\n",
    "                    tempDiffMat = abs(tempQueryMat-midPivotMat)\n",
    "                    \n",
    "                    # being in uint8, with 3 channels, let's look for similarity\n",
    "                    # (7*1*3 = 21 comparison pixel window)\n",
    "                    if sum(sum(tempDiffMat)) < 10*tempDiffMat.size:\n",
    "                        # in the case of a close preliminary match, we'll expand the\n",
    "                        # compare to a much bigger window.\n",
    "                        qRS = midRowPivot - maxHeightPush + tempYOffset\n",
    "                        qRE = midRowPivot + maxHeightPush + tempYOffset\n",
    "                        \n",
    "                        bigQueryMat = queryFrag[qRS:qRE,tempQueryXIdx,:].astype('int32')    \n",
    "                        tempDiffMat = abs(bigQueryMat-bigPivotMat)\n",
    "                        \n",
    "                        if sum(sum(tempDiffMat)) <= 5*tempDiffMat.size:\n",
    "                            # in the case of a 'big match' we'll tunnel even further\n",
    "                            # and see if the match continues.\n",
    "                            \n",
    "                            for xTunnel in range(1,tunnelDepth):\n",
    "                                bigQueryMat = queryFrag[qRS:qRE,tempQueryXIdx+xTunnel,:].astype('int32')\n",
    "                                bigPivotMatTemp = (pivotFrag[midRowPivot-maxHeightPush:midRowPivot+maxHeightPush,\n",
    "                                                         xTunnel,:]).astype('int32')\n",
    "                                tempDiffMat = abs(bigQueryMat-bigPivotMatTemp)\n",
    "                                \n",
    "                                if sum(sum(tempDiffMat)) > 2*tempDiffMat.size:\n",
    "                                    break\n",
    "                                elif xTunnel == tunnelDepth-1 :\n",
    "                                    # remember that we're in the right-pivot-to-left-query\n",
    "                                    # comparison scheme right here.\n",
    "                                    fragmentGraph[i,0,0] = j\n",
    "                                    fragmentGraph[i,0,1] = fragsWidth-tempQueryXIdx\n",
    "                                    fragmentGraph[i,0,2] = tempYOffset\n",
    "                                    bigBreak = True;\n",
    "                    \n",
    "                    # if we've found a match, break from the grind in Y and go\n",
    "                    # to next pivot fragment (this'll take a couple break statements)\n",
    "                    if(bigBreak):\n",
    "                        break\n",
    "                    else:\n",
    "                        tempYOffset += 1\n",
    "                \n",
    "                # if we've found a match, break from the grind in X tunneling\n",
    "                if(bigBreak):\n",
    "                    break\n",
    "                else:\n",
    "                    tempQueryXIdx -= 1\n",
    "            \n",
    "            # here's the limit of the i/j frag pair testing (if i != j)\n",
    "        \n",
    "        # now, IMPORTANT: if we've found a match and reached here, we\n",
    "        # DON'T want to break but rather CONTINUE to the next pivot fragment.\n",
    "        if(bigBreak):\n",
    "            continue\n",
    "            \n",
    "################################################\n",
    "### DETERMINING ABOVE -> BELOW RELATIONSHIPS ###\n",
    "################################################\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    # starting by designating a current \"pivot\" position\n",
    "    # where we're determining key graph relationships\n",
    "    pivotFrag = pixFrags[i,:,:,:]\n",
    "    \n",
    "    for j in range(0,numFragments):\n",
    "        # don't want to compare to self!\n",
    "        \n",
    "        bigBreak = False\n",
    "        \n",
    "        if j != i:\n",
    "            # let's begin in the middle of the two images and\n",
    "            # try tentative offsets/matching data subsequences from there.\n",
    "            queryFrag = pixFrags[j,:,:,:]\n",
    "            \n",
    "            # for this preliminary trial, we'll pivot on the outermost\n",
    "            # rows and columns of pivotFrag's data, probing for matching\n",
    "            # subsequences in queryFrag (where we'll have to look through\n",
    "            # a non-trivial range of columns and rows (due to overlap/offset))\n",
    "            \n",
    "            # declaring bounds for subsequence search\n",
    "            maxMatchWidth = colInterval//2\n",
    "            maxMatchHeight = rowInterval//2\n",
    "            \n",
    "            maxWidthPush = maxMatchWidth//2\n",
    "            maxHeightPush = maxMatchHeight//2\n",
    "            \n",
    "            # let's start comparing the right side of pivotFrag\n",
    "            # with the left side of queryFrag.\n",
    "            midRowPivot = fragsHeight//2\n",
    "            midColPivot = fragsWidth//2\n",
    "            \n",
    "            # looking for small comparison subsets at first (then building out to confirm)\n",
    "            midPivotMat = (pivotFrag[fragsHeight-1,midColPivot-3:midColPivot+3,:]\n",
    "                           .astype('int32'))\n",
    "            bigPivotMat = (pivotFrag[fragsHeight-1,\n",
    "                                     midColPivot-maxWidthPush:midColPivot+maxWidthPush,:]).astype('int32')\n",
    "            \n",
    "            tempQueryYIdx = tunnelDepth\n",
    "            \n",
    "            # regarding limits of the search: we may have to 'tunnel' as much as\n",
    "            # 3*overlapPix pixels + 2*offsetMax into the neighbor to find a match due to how\n",
    "            # these overlaps work near the original image boundary.\n",
    "            \n",
    "            # NOTE: the situation is different if we only have 2 row partitions!!!\n",
    "            #       need to push y all the way to 4*overlapPix!\n",
    "            yOverlapFactor = 3\n",
    "            if rowPartitions == 2:\n",
    "                yOverlapFactor = 4\n",
    "            \n",
    "            # Note the reversal of roles for x/y offsets here compared to left/right relationships.\n",
    "            while tempQueryYIdx < yOverlapFactor*overlapPix + 2 + 2*offsetMax:\n",
    "                \n",
    "                tempXOffset = -3*offsetMax\n",
    "                while tempXOffset < 3*offsetMax + 2:\n",
    "                    \n",
    "                    qCS = midColPivot - 3 + tempXOffset\n",
    "                    qCE = midColPivot + 3 + tempXOffset\n",
    "\n",
    "                    # what we're creating here is an initial comparison\n",
    "                    # sliding window of 7 pixels total (3 up, 3 down).\n",
    "                    # if these are \"close enough\" to each other, we'll push\n",
    "                    # the comparison out to try and verify a match.\n",
    "                    \n",
    "                    # let's try and anticipate some possible corruption/bias in our\n",
    "                    # comparison here.\n",
    "                    tempQueryMat = queryFrag[tempQueryYIdx,qCS:qCE,:].astype('int32')\n",
    "                    tempDiffMat = abs(tempQueryMat-midPivotMat)\n",
    "                    \n",
    "                    # being in uint8, with 3 channels, let's look for similarity\n",
    "                    # (7*1*3 = 21 comparison pixel window)\n",
    "                    if sum(sum(tempDiffMat)) < 10*tempDiffMat.size:\n",
    "                        # in the case of a close preliminary match, we'll expand the\n",
    "                        # compare to a much bigger window.\n",
    "                        qCS = midColPivot - maxWidthPush + tempXOffset\n",
    "                        qCE = midColPivot + maxWidthPush + tempXOffset\n",
    "                        \n",
    "                        bigQueryMat = queryFrag[tempQueryYIdx,qCS:qCE,:].astype('int32')    \n",
    "                        tempDiffMat = abs(bigQueryMat-bigPivotMat)\n",
    "                        \n",
    "                        if sum(sum(tempDiffMat)) <= 5*tempDiffMat.size:\n",
    "                            # in the case of a 'big match' we'll tunnel even further\n",
    "                            # and see if the match continues.\n",
    "                            \n",
    "                            for yTunnel in range(1,tunnelDepth):\n",
    "                                bigQueryMat = queryFrag[tempQueryYIdx-yTunnel,qCS:qCE,:].astype('int32')\n",
    "                                bigPivotMatTemp = (pivotFrag[fragsHeight-1-yTunnel,\n",
    "                                                             midColPivot-maxWidthPush:midColPivot+maxWidthPush,\n",
    "                                                             :]).astype('int32')\n",
    "                                tempDiffMat = abs(bigQueryMat-bigPivotMatTemp)\n",
    "                                \n",
    "                                if sum(sum(tempDiffMat)) > 2*tempDiffMat.size:\n",
    "                                    break\n",
    "                                elif yTunnel == tunnelDepth-1 :\n",
    "                                    # remember that we're in the left-pivot-to-right-query\n",
    "                                    # comparison scheme right here.\n",
    "                                    fragmentGraph[i,3,0] = j\n",
    "                                    fragmentGraph[i,3,1] = tempXOffset\n",
    "                                    fragmentGraph[i,3,2] = tempQueryYIdx\n",
    "                                    bigBreak = True;\n",
    "                    \n",
    "                    # if we've found a match, break from the grind in Y and go\n",
    "                    # to next pivot fragment (this'll take a couple break statements)\n",
    "                    if(bigBreak):\n",
    "                        break\n",
    "                    else:\n",
    "                        tempXOffset += 1\n",
    "                \n",
    "                # if we've found a match, break from the grind in X tunneling\n",
    "                if(bigBreak):\n",
    "                    break\n",
    "                else:\n",
    "                    tempQueryYIdx += 1\n",
    "            \n",
    "            # here's the limit of the i/j frag pair testing (if i != j)\n",
    "        \n",
    "        # now, IMPORTANT: if we've found a match and reached here, we\n",
    "        # DON'T want to break but rather CONTINUE to the next pivot fragment.\n",
    "        if(bigBreak):\n",
    "            continue\n",
    "            \n",
    "################################################\n",
    "### DETERMINING BELOW -> ABOVE RELATIONSHIPS ###\n",
    "################################################\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    # starting by designating a current \"pivot\" position\n",
    "    # where we're determining key graph relationships\n",
    "    pivotFrag = pixFrags[i,:,:,:]\n",
    "    \n",
    "    for j in range(0,numFragments):\n",
    "        # don't want to compare to self!\n",
    "        \n",
    "        bigBreak = False\n",
    "        \n",
    "        if j != i:\n",
    "            # let's begin in the middle of the two images and\n",
    "            # try tentative offsets/matching data subsequences from there.\n",
    "            queryFrag = pixFrags[j,:,:,:]\n",
    "            \n",
    "            # for this preliminary trial, we'll pivot on the outermost\n",
    "            # rows and columns of pivotFrag's data, probing for matching\n",
    "            # subsequences in queryFrag (where we'll have to look through\n",
    "            # a non-trivial range of columns and rows (due to overlap/offset))\n",
    "            \n",
    "            # declaring bounds for subsequence search\n",
    "            maxMatchWidth = colInterval//2\n",
    "            maxMatchHeight = rowInterval//2\n",
    "            \n",
    "            maxWidthPush = maxMatchWidth//2\n",
    "            maxHeightPush = maxMatchHeight//2\n",
    "            \n",
    "            # let's start comparing the right side of pivotFrag\n",
    "            # with the left side of queryFrag.\n",
    "            midRowPivot = fragsHeight//2\n",
    "            midColPivot = fragsWidth//2\n",
    "            \n",
    "            # looking for small comparison subsets at first (then building out to confirm)\n",
    "            midPivotMat = (pivotFrag[0,midColPivot-3:midColPivot+3,:]\n",
    "                           .astype('int32'))\n",
    "            bigPivotMat = (pivotFrag[0,\n",
    "                                     midColPivot-maxWidthPush:midColPivot+maxWidthPush,:]).astype('int32')\n",
    "            \n",
    "            tempQueryYIdx = fragsHeight-1-tunnelDepth\n",
    "            \n",
    "            # regarding limits of the search: we may have to 'tunnel' as much as\n",
    "            # 3*overlapPix pixels + 2*offsetMax into the neighbor to find a match due to how\n",
    "            # these overlaps work near the original image boundary.\n",
    "            \n",
    "            # NOTE: the situation is different if we only have 2 row partitions!!!\n",
    "            #       need to push y all the way to 4*overlapPix!\n",
    "            yOverlapFactor = 3\n",
    "            if rowPartitions == 2:\n",
    "                yOverlapFactor = 4\n",
    "            \n",
    "            # Note the reversal of roles for x/y offsets here compared to left/right relationships.\n",
    "            while tempQueryYIdx > fragsHeight-1- (yOverlapFactor*overlapPix + 2 + 2*offsetMax):\n",
    "                \n",
    "                tempXOffset = -3*offsetMax\n",
    "                while tempXOffset < 3*offsetMax + 2:\n",
    "                    \n",
    "                    qCS = midColPivot - 3 + tempXOffset\n",
    "                    qCE = midColPivot + 3 + tempXOffset\n",
    "\n",
    "                    # what we're creating here is an initial comparison\n",
    "                    # sliding window of 7 pixels total (3 up, 3 down).\n",
    "                    # if these are \"close enough\" to each other, we'll push\n",
    "                    # the comparison out to try and verify a match.\n",
    "                    \n",
    "                    # let's try and anticipate some possible corruption/bias in our\n",
    "                    # comparison here.\n",
    "                    tempQueryMat = queryFrag[tempQueryYIdx,qCS:qCE,:].astype('int32')\n",
    "                    tempDiffMat = abs(tempQueryMat-midPivotMat)\n",
    "                    \n",
    "                    # being in uint8, with 3 channels, let's look for similarity\n",
    "                    # (7*1*3 = 21 comparison pixel window)\n",
    "                    if sum(sum(tempDiffMat)) < 10*tempDiffMat.size:\n",
    "                        # in the case of a close preliminary match, we'll expand the\n",
    "                        # compare to a much bigger window.\n",
    "                        qCS = midColPivot - maxWidthPush + tempXOffset\n",
    "                        qCE = midColPivot + maxWidthPush + tempXOffset\n",
    "                        \n",
    "                        bigQueryMat = queryFrag[tempQueryYIdx,qCS:qCE,:].astype('int32')    \n",
    "                        tempDiffMat = abs(bigQueryMat-bigPivotMat)\n",
    "                        \n",
    "                        if sum(sum(tempDiffMat)) <= 5*tempDiffMat.size:\n",
    "                            # in the case of a 'big match' we'll tunnel even further\n",
    "                            # and see if the match continues.\n",
    "                            \n",
    "                            for yTunnel in range(1,tunnelDepth):\n",
    "                                bigQueryMat = queryFrag[tempQueryYIdx+yTunnel,qCS:qCE,:].astype('int32')\n",
    "                                bigPivotMatTemp = (pivotFrag[yTunnel,\n",
    "                                                             midColPivot-maxWidthPush:midColPivot+maxWidthPush,\n",
    "                                                             :]).astype('int32')\n",
    "                                tempDiffMat = abs(bigQueryMat-bigPivotMatTemp)\n",
    "                                \n",
    "                                if sum(sum(tempDiffMat)) > 2*tempDiffMat.size:\n",
    "                                    break\n",
    "                                elif yTunnel == tunnelDepth-1 :\n",
    "                                    # remember that we're in the left-pivot-to-right-query\n",
    "                                    # comparison scheme right here.\n",
    "                                    fragmentGraph[i,2,0] = j\n",
    "                                    fragmentGraph[i,2,1] = tempXOffset\n",
    "                                    fragmentGraph[i,2,2] = tempQueryYIdx-fragsHeight\n",
    "                                    bigBreak = True;\n",
    "                    \n",
    "                    # if we've found a match, break from the grind in Y and go\n",
    "                    # to next pivot fragment (this'll take a couple break statements)\n",
    "                    if(bigBreak):\n",
    "                        break\n",
    "                    else:\n",
    "                        tempXOffset += 1\n",
    "                \n",
    "                # if we've found a match, break from the grind in X tunneling\n",
    "                if(bigBreak):\n",
    "                    break\n",
    "                else:\n",
    "                    tempQueryYIdx -= 1\n",
    "            \n",
    "            # here's the limit of the i/j frag pair testing (if i != j)\n",
    "        \n",
    "        # now, IMPORTANT: if we've found a match and reached here, we\n",
    "        # DON'T want to break but rather CONTINUE to the next pivot fragment.\n",
    "        if(bigBreak):\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# comparing vs. true graph (with/without offsets)\n",
    "#print(fragmentGraph)\n",
    "#print(fragmentGraph[:,0:4,0])\n",
    "#print(trueGraph)\n",
    "#print(fragmentGraph[:,0:4,0]-trueGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's now build an ordering for the photos based on everything being done\n",
    "# correctly (for now).\n",
    "reducedGraph = fragmentGraph[:,0:4,0]\n",
    "\n",
    "# finding the top-left element\n",
    "tlIndex = 0\n",
    "for i in range(0,numFragments):\n",
    "    if reducedGraph[i,0] == -1 and reducedGraph[i,2] == -1:\n",
    "        tlIndex = i\n",
    "        break\n",
    "        \n",
    "# building left to right, row by row\n",
    "restoredIndices = -1*np.ones(numFragments,dtype='int')\n",
    "restoredIndices[0] = tlIndex\n",
    "\n",
    "for i in range(1,numFragments):\n",
    "    if(i % colPartitions == 0):\n",
    "        # new row: grabbing index from data above\n",
    "        restoredIndices[i] = reducedGraph[restoredIndices[i-colPartitions],3]\n",
    "    else:\n",
    "        restoredIndices[i] = reducedGraph[restoredIndices[i-1],1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reconstructing image. NOTE: offsets and overlap slightly cheated for now\n",
    "# for printing purposes.\n",
    "pixReconstructed = np.zeros((rowInterval*rowPartitions,colInterval*colPartitions,3),dtype = 'uint8')\n",
    "\n",
    "for i in range(0,numFragments):\n",
    "    blockRowInd = i // colPartitions\n",
    "    blockColInd = i % colPartitions\n",
    "    \n",
    "    startRow = rowInterval*blockRowInd\n",
    "    endRow = startRow + rowInterval\n",
    "    \n",
    "    startCol = colInterval*blockColInd\n",
    "    endCol = startCol + colInterval\n",
    "    \n",
    "    fragRS = overlapPix\n",
    "    fragRE = rowInterval + overlapPix\n",
    "\n",
    "    fragCS = overlapPix\n",
    "    fragCE = colInterval + overlapPix\n",
    "\n",
    "    pixReconstructed[startRow:endRow,startCol:endCol,:] = pixFrags[restoredIndices[i],fragRS:fragRE,fragCS:fragCE,:]\n",
    "    \n",
    "# row partitions\n",
    "for i in range(1,rowPartitions):\n",
    "    rowBegin = i*rowInterval-4\n",
    "    rowEnd   = i*rowInterval+5\n",
    "    pixReconstructed[rowBegin:rowEnd,:,:] = 255\n",
    "        \n",
    "# column partitions\n",
    "for j in range(1,colPartitions):\n",
    "    colBegin = j*colInterval-4\n",
    "    colEnd   = j*colInterval+5\n",
    "    pixReconstructed[:,colBegin:colEnd,:] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "imReconstructed = Image.fromarray(pixReconstructed)\n",
    "#imReconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
